

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>pyrfm: A library for random feature maps in Python. &mdash; pyrfm 0.1.0dev documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
        <script type="text/javascript" src="_static/language_data.js"></script>
        <script async="async" type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Linear models" href="linear_model.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="#" class="icon icon-home"> pyrfm
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">API-References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="linear_model.html">Linear models</a></li>
<li class="toctree-l1"><a class="reference internal" href="random_feature.html">Random features</a></li>
<li class="toctree-l1"><a class="reference internal" href="kernel.html">Kernel functions</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="#">pyrfm</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="#">Docs</a> &raquo;</li>
        
      <li>pyrfm: A library for random feature maps in Python.</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/index.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="pyrfm-a-library-for-random-feature-maps-in-python">
<h1>pyrfm: A library for random feature maps in Python.<a class="headerlink" href="#pyrfm-a-library-for-random-feature-maps-in-python" title="Permalink to this headline">¶</a></h1>
</div>
<div class="section" id="pyrfm">
<h1>pyrfm<a class="headerlink" href="#pyrfm" title="Permalink to this headline">¶</a></h1>
<p>A library for random feature maps and linear models with random feature
maps in Python.</p>
<div class="section" id="installation">
<h2>Installation<a class="headerlink" href="#installation" title="Permalink to this headline">¶</a></h2>
<ol class="arabic">
<li><p>Download the source codes by:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">git</span> <span class="n">clone</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">neonnnnn</span><span class="o">/</span><span class="n">pyrfm</span><span class="o">.</span><span class="n">git</span>
</pre></div>
</div>
</li>
</ol>
<p>or download as a ZIP from GitHub.</p>
<ol class="arabic" start="2">
<li><p>Install the dependencies::</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cd</span> <span class="n">pyrfm</span>

<span class="n">pip</span> <span class="n">install</span> <span class="o">-</span><span class="n">r</span> <span class="n">requirements</span><span class="o">.</span><span class="n">txt</span>
</pre></div>
</div>
</li>
<li><p>Finally, build and install pyrfm by:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="n">setup</span><span class="o">.</span><span class="n">py</span> <span class="n">install</span>
</pre></div>
</div>
</li>
</ol>
</div>
<div class="section" id="what-are-random-feature-maps">
<h2>What are random feature maps?<a class="headerlink" href="#what-are-random-feature-maps" title="Permalink to this headline">¶</a></h2>
<p>Random feature maps are promising methods for large-scale kernel methods.
They are maps from a original feature space to a randomized feature space approximating a kernel-induced feature space.
The idea is to run linear models on such randomized feature space for classification, regression, clustering, etc.
When the dimension of the random feature map D is not so high and the number of training example N is large, this approach is very efficient compared to canonical kernel methods.</p>
</div>
<div class="section" id="random-feature-maps-implemented">
<h2>Random Feature Maps Implemented<a class="headerlink" href="#random-feature-maps-implemented" title="Permalink to this headline">¶</a></h2>
<p>pyrfm follows the scikit-learn API and now <strong>supports following random features</strong>.</p>
<ul class="simple">
<li><p><a class="reference internal" href="generated/pyrfm.random_feature.RandomFourier.html#pyrfm.random_feature.RandomFourier" title="pyrfm.random_feature.RandomFourier"><code class="xref py py-class docutils literal notranslate"><span class="pre">RandomFourier</span></code></a>: random Fourier feature (for the RBF kernel) <a class="bibtex reference internal" href="#rahimi2008random" id="id1">[RR08]</a></p></li>
<li><p><a class="reference internal" href="generated/pyrfm.random_feature.RandomMaclaurin.html#pyrfm.random_feature.RandomMaclaurin" title="pyrfm.random_feature.RandomMaclaurin"><code class="xref py py-class docutils literal notranslate"><span class="pre">RandomMaclaurin</span></code></a>: random Maclaurin feature (for the polynomial kernel, exp kernel, and user-specified dot product kernels) <a class="bibtex reference internal" href="#kar2012random" id="id2">[KK12]</a></p></li>
<li><p><a class="reference internal" href="generated/pyrfm.random_feature.TensorSketch.html#pyrfm.random_feature.TensorSketch" title="pyrfm.random_feature.TensorSketch"><code class="xref py py-class docutils literal notranslate"><span class="pre">TensorSketch</span></code></a>: tensor sketching (for the polynomial kernel) <a class="bibtex reference internal" href="#pham2013fast" id="id3">[PP13]</a></p></li>
<li><p><a class="reference internal" href="generated/pyrfm.random_feature.RandomKernel.html#pyrfm.random_feature.RandomKernel" title="pyrfm.random_feature.RandomKernel"><code class="xref py py-class docutils literal notranslate"><span class="pre">RandomKernel</span></code></a>: random kernel feature (for the ANOVA kernel and all-subsets kernel) <a class="bibtex reference internal" href="#atarashi2019random" id="id4">[ASO19]</a></p></li>
<li><p><a class="reference internal" href="generated/pyrfm.random_feature.MB.html#pyrfm.random_feature.MB" title="pyrfm.random_feature.MB"><code class="xref py py-class docutils literal notranslate"><span class="pre">MB</span></code></a>: S.Maji and A.Berg feature (for the intersection (min) kernel) (this feature is not random) <a class="bibtex reference internal" href="#maji2009max" id="id5">[MB09]</a></p></li>
</ul>
<p>In other words, pyrfm now <strong>provides approximaters for following kernels</strong>.</p>
<ul class="simple">
<li><p>RBF kernel (<a class="reference internal" href="generated/pyrfm.random_feature.RandomFourier.html#pyrfm.random_feature.RandomFourier" title="pyrfm.random_feature.RandomFourier"><code class="xref py py-class docutils literal notranslate"><span class="pre">RandomFourier</span></code></a>)</p></li>
<li><p>polynomial kernel (<a class="reference internal" href="generated/pyrfm.random_feature.RandomMaclaurin.html#pyrfm.random_feature.RandomMaclaurin" title="pyrfm.random_feature.RandomMaclaurin"><code class="xref py py-class docutils literal notranslate"><span class="pre">RandomMaclaurin</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">TensorSketching</span></code>)</p></li>
<li><p>exponential kernel (<a class="reference internal" href="generated/pyrfm.random_feature.RandomMaclaurin.html#pyrfm.random_feature.RandomMaclaurin" title="pyrfm.random_feature.RandomMaclaurin"><code class="xref py py-class docutils literal notranslate"><span class="pre">RandomMaclaurin</span></code></a>)</p></li>
<li><p>user-specified dot product kernel (<a class="reference internal" href="generated/pyrfm.random_feature.RandomMaclaurin.html#pyrfm.random_feature.RandomMaclaurin" title="pyrfm.random_feature.RandomMaclaurin"><code class="xref py py-class docutils literal notranslate"><span class="pre">RandomMaclaurin</span></code></a>, requiring Maclaurin coefficients of specified kernel)</p></li>
<li><p>ANOVA kernel (<a class="reference internal" href="generated/pyrfm.random_feature.RandomKernel.html#pyrfm.random_feature.RandomKernel" title="pyrfm.random_feature.RandomKernel"><code class="xref py py-class docutils literal notranslate"><span class="pre">RandomKernel</span></code></a>)</p></li>
<li><p>all-subsets kernel (<a class="reference internal" href="generated/pyrfm.random_feature.RandomKernel.html#pyrfm.random_feature.RandomKernel" title="pyrfm.random_feature.RandomKernel"><code class="xref py py-class docutils literal notranslate"><span class="pre">RandomKernel</span></code></a>)</p></li>
<li><p>intersection (min) kernel (<a class="reference internal" href="generated/pyrfm.random_feature.MB.html#pyrfm.random_feature.MB" title="pyrfm.random_feature.MB"><code class="xref py py-class docutils literal notranslate"><span class="pre">MB</span></code></a>)</p></li>
</ul>
<p>The random Fourier feature is also implemented in scikit-learn (<code class="docutils literal notranslate"><span class="pre">kernel_approximation.RBFSampler</span></code>).</p>
<p>Furthermore, pyrfm <strong>supports following structured random features</strong>.</p>
<ul class="simple">
<li><p><a class="reference internal" href="generated/pyrfm.random_feature.SignedCirculantRandomMatrix.html#pyrfm.random_feature.SignedCirculantRandomMatrix" title="pyrfm.random_feature.SignedCirculantRandomMatrix"><code class="xref py py-class docutils literal notranslate"><span class="pre">SignedCirculantRandomMatrix</span></code></a>: signed circulant random matrix (for the dot product / RBF kernel) <a class="bibtex reference internal" href="#feng2015random" id="id6">[FHL15]</a></p></li>
<li><p><a class="reference internal" href="generated/pyrfm.random_feature.SignedCirculantRandomKernel.html#pyrfm.random_feature.SignedCirculantRandomKernel" title="pyrfm.random_feature.SignedCirculantRandomKernel"><code class="xref py py-class docutils literal notranslate"><span class="pre">SignedCirculantRandomKernel</span></code></a>: signed circulant random kernel feature (for the ANOVA kernel) <a class="bibtex reference internal" href="#atarashi2019random" id="id7">[ASO19]</a></p></li>
<li><p><a class="reference internal" href="generated/pyrfm.random_feature.SubsampledRandomHadamard.html#pyrfm.random_feature.SubsampledRandomHadamard" title="pyrfm.random_feature.SubsampledRandomHadamard"><code class="xref py py-class docutils literal notranslate"><span class="pre">SubsampledRandomHadamard</span></code></a>: subsampled random Hadamard transform (for the dot product) <a class="bibtex reference internal" href="#tropp2011improved" id="id8">[Tro11]</a></p></li>
<li><p><a class="reference internal" href="generated/pyrfm.random_feature.FastFood.html#pyrfm.random_feature.FastFood" title="pyrfm.random_feature.FastFood"><code class="xref py py-class docutils literal notranslate"><span class="pre">FastFood</span></code></a>: fastfood (for the dot product / RBF kernel) <a class="bibtex reference internal" href="#le2013fastfood" id="id9">[LSarlosS13]</a></p></li>
<li><p><a class="reference internal" href="generated/pyrfm.random_feature.CompactRandomFeature.html#pyrfm.random_feature.CompactRandomFeature" title="pyrfm.random_feature.CompactRandomFeature"><code class="xref py py-class docutils literal notranslate"><span class="pre">CompactRandomFeature</span></code></a>: compact random features <a class="bibtex reference internal" href="#hamid2014compact" id="id10">[HXGD14]</a> (with subsampled ranadom Hadamard transform or random projection <a class="bibtex reference internal" href="#li2006very" id="id11">[LHC06]</a>)</p></li>
<li><p><a class="reference internal" href="generated/pyrfm.random_feature.OrthogonalRandomFeature.html#pyrfm.random_feature.OrthogonalRandomFeature" title="pyrfm.random_feature.OrthogonalRandomFeature"><code class="xref py py-class docutils literal notranslate"><span class="pre">OrthogonalRandomFeature</span></code></a> / <a class="reference internal" href="generated/pyrfm.random_feature.StructuredOrthogonalRandomFeature.html#pyrfm.random_feature.StructuredOrthogonalRandomFeature" title="pyrfm.random_feature.StructuredOrthogonalRandomFeature"><code class="xref py py-class docutils literal notranslate"><span class="pre">StructuredOrthogonalRandomFeature</span></code></a>: orthogonal random feature / structured orthogonal random feature (for the dot product / RBF kernel) <a class="bibtex reference internal" href="#yu2016orthogonal" id="id12">[YSC+16]</a></p></li>
</ul>
<p>These methods are faster and more memory-efficient than canonical random features such as random Fourier, random kernel, etc.
We believe that you can use these structured random features as a subroutine of your proposed random features, and <a class="reference internal" href="generated/pyrfm.random_feature.SignedCirculantRandomKernel.html#pyrfm.random_feature.SignedCirculantRandomKernel" title="pyrfm.random_feature.SignedCirculantRandomKernel"><code class="xref py py-class docutils literal notranslate"><span class="pre">SignedCirculantRandomKernel</span></code></a> is an example of it (<a class="reference internal" href="generated/pyrfm.random_feature.SignedCirculantRandomMatrix.html#pyrfm.random_feature.SignedCirculantRandomMatrix" title="pyrfm.random_feature.SignedCirculantRandomMatrix"><code class="xref py py-class docutils literal notranslate"><span class="pre">SignedCirculantRandomMatrix</span></code></a> is used as a subroutine).</p>
</div>
<div class="section" id="linear-models-implemented">
<h2>Linear Models Implemented<a class="headerlink" href="#linear-models-implemented" title="Permalink to this headline">¶</a></h2>
<p>Moreover, pyrfm <strong>supports following solvers for linear models with random features</strong>.</p>
<ul class="simple">
<li><p><a class="reference internal" href="generated/pyrfm.linear_model.SparseMBRegressor.html#pyrfm.linear_model.SparseMBRegressor" title="pyrfm.linear_model.SparseMBRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">SparseMBRegressor</span></code></a> / <a class="reference internal" href="generated/pyrfm.linear_model.SparseMBClassifier.html#pyrfm.linear_model.SparseMBClassifier" title="pyrfm.linear_model.SparseMBClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">SparseMBClassifier</span></code></a>: primal coordinate descent for sparse S.Maji and A.Berg feature <a class="bibtex reference internal" href="#maji2009max" id="id13">[MB09]</a> <a class="bibtex reference internal" href="#chang2008coordinate" id="id14">[CHL08]</a></p></li>
<li><p><a class="reference internal" href="generated/pyrfm.linear_model.AdaGradRegressor.html#pyrfm.linear_model.AdaGradRegressor" title="pyrfm.linear_model.AdaGradRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">AdaGradRegressor</span></code></a> / <a class="reference internal" href="generated/pyrfm.linear_model.AdaGradClassifier.html#pyrfm.linear_model.AdaGradClassifier" title="pyrfm.linear_model.AdaGradClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">AdaGradClassifier</span></code></a>: AdaGrad for very-large-scale dataset: does not compute the random feature map of all examples at the same time (space efficient but slow) <a class="bibtex reference internal" href="#duchi2011adaptive" id="id15">[DHS11]</a></p></li>
<li><p><a class="reference internal" href="generated/pyrfm.linear_model.SDCARegressor.html#pyrfm.linear_model.SDCARegressor" title="pyrfm.linear_model.SDCARegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">SDCARegressor</span></code></a> / <a class="reference internal" href="generated/pyrfm.linear_model.SDCAClassifier.html#pyrfm.linear_model.SDCAClassifier" title="pyrfm.linear_model.SDCAClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">SDCAClassifier</span></code></a>: SDCA for very-large-scale dataset: does not compute the random feature map of all examples at the same time (space efficient but slow) <a class="bibtex reference internal" href="#shalev2013stochastic" id="id16">[SSZ13]</a></p></li>
<li><p><a class="reference internal" href="generated/pyrfm.linear_model.AdamRegressor.html#pyrfm.linear_model.AdamRegressor" title="pyrfm.linear_model.AdamRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">AdamRegressor</span></code></a> / <a class="reference internal" href="generated/pyrfm.linear_model.AdamClassifier.html#pyrfm.linear_model.AdamClassifier" title="pyrfm.linear_model.AdamClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">AdamClassifier</span></code></a>: Adam for very-large-scale dataset: does not compute the random feature map of all examples at the same time (space efficient but slow) <a class="bibtex reference internal" href="#kingma2014adam" id="id17">[KB15]</a></p></li>
<li><p><a class="reference internal" href="generated/pyrfm.linear_model.SGDRegressor.html#pyrfm.linear_model.SGDRegressor" title="pyrfm.linear_model.SGDRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">SGDRegressor</span></code></a> / <a class="reference internal" href="generated/pyrfm.linear_model.SGDClassifier.html#pyrfm.linear_model.SGDClassifier" title="pyrfm.linear_model.SGDClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">SGDClassifier</span></code></a>: SGD/ASGD for very-large-scale dataset: does not compute the random feature map of all examples at the same time (space efficient but slow) <a class="bibtex reference internal" href="#bottou2010large" id="id18">[Bot10]</a> <a class="bibtex reference internal" href="#bottou2012stochastic" id="id19">[Bot12]</a></p></li>
<li><p><a class="reference internal" href="generated/pyrfm.linear_model.SAGARegressor.html#pyrfm.linear_model.SAGARegressor" title="pyrfm.linear_model.SAGARegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">SAGARegressor</span></code></a> / <a class="reference internal" href="generated/pyrfm.linear_model.SAGAClassifier.html#pyrfm.linear_model.SAGAClassifier" title="pyrfm.linear_model.SAGAClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">SAGAClassifier</span></code></a>: SAG/SAGA for very-large-scale dataset: does not compute the random feature map of all examples at the same time (space efficient but slow) <a class="bibtex reference internal" href="#defazio2014saga" id="id20">[DBLJ14]</a> <a class="bibtex reference internal" href="#schmidt2017minimizing" id="id21">[SLRB17]</a></p></li>
</ul>
<p>All methods support squared loss for regression and hinge loss, squared hinge loss, and logistic loss for classification.</p>
<p>AdaGrad, SDCA, Adam, SGD/ASGD, and SAG/SAGA in pyrfm are for a very-large-scale dataset such that computing its random feature matrix (i.e., computing random features for all instances at the same time) causes MemoryError.
If you can allocate memory for random feature matrix of your training data, you should use the other implementations of linear models (linear_model in scikit-learn, sklearn-contrib-lightning, etc).</p>
<p>Now, these stochastic solvers run efficiently for following random features.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">RBFSampler</span></code> (in sklearn.kernel_approximation)</p></li>
<li><p><a class="reference internal" href="generated/pyrfm.random_feature.RandomFourier.html#pyrfm.random_feature.RandomFourier" title="pyrfm.random_feature.RandomFourier"><code class="xref py py-class docutils literal notranslate"><span class="pre">RandomFourier</span></code></a></p></li>
<li><p><a class="reference internal" href="generated/pyrfm.random_feature.RandomMaclaurin.html#pyrfm.random_feature.RandomMaclaurin" title="pyrfm.random_feature.RandomMaclaurin"><code class="xref py py-class docutils literal notranslate"><span class="pre">RandomMaclaurin</span></code></a></p></li>
<li><p><a class="reference internal" href="generated/pyrfm.random_feature.TensorSketch.html#pyrfm.random_feature.TensorSketch" title="pyrfm.random_feature.TensorSketch"><code class="xref py py-class docutils literal notranslate"><span class="pre">TensorSketch</span></code></a></p></li>
<li><p><a class="reference internal" href="generated/pyrfm.random_feature.RandomKernel.html#pyrfm.random_feature.RandomKernel" title="pyrfm.random_feature.RandomKernel"><code class="xref py py-class docutils literal notranslate"><span class="pre">RandomKernel</span></code></a></p></li>
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">SignedCirculantRandomProjection</span></code></p></li>
<li><p><a class="reference internal" href="generated/pyrfm.random_feature.FastFood.html#pyrfm.random_feature.FastFood" title="pyrfm.random_feature.FastFood"><code class="xref py py-class docutils literal notranslate"><span class="pre">FastFood</span></code></a></p></li>
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">SubsampledRandomHadamardTransform</span></code></p></li>
<li><p><a class="reference internal" href="generated/pyrfm.random_feature.CompactRandomFeature.html#pyrfm.random_feature.CompactRandomFeature" title="pyrfm.random_feature.CompactRandomFeature"><code class="xref py py-class docutils literal notranslate"><span class="pre">CompactRandomFeature</span></code></a></p></li>
<li><p><a class="reference internal" href="generated/pyrfm.random_feature.OrthogonalRandomFeature.html#pyrfm.random_feature.OrthogonalRandomFeature" title="pyrfm.random_feature.OrthogonalRandomFeature"><code class="xref py py-class docutils literal notranslate"><span class="pre">OrthogonalRandomFeature</span></code></a> / <a class="reference internal" href="generated/pyrfm.random_feature.StructuredOrthogonalRandomFeature.html#pyrfm.random_feature.StructuredOrthogonalRandomFeature" title="pyrfm.random_feature.StructuredOrthogonalRandomFeature"><code class="xref py py-class docutils literal notranslate"><span class="pre">StructuredOrthogonalRandomFeature</span></code></a></p></li>
</ul>
<p>For improving efficiency, implement cdef class and cdef transform method for your desired transformer.
Please see <code class="docutils literal notranslate"><span class="pre">random_feature/random_features_fast.pyx/pxd</span></code>.
Although these stochastic solvers <strong>support any transformers, they might run unbelievable slow</strong> when there is no cdef class and cdef transform method for your desired transformer in <code class="docutils literal notranslate"><span class="pre">random_features_fast.pyx</span></code>.
We believe that these implementations can be used for researches.</p>
</div>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<p id="bibtex-bibliography-index-0"><dl class="citation">
<dt class="bibtex label" id="atarashi2019random"><span class="brackets">ASO19</span><span class="fn-backref">(<a href="#id4">1</a>,<a href="#id7">2</a>)</span></dt>
<dd><p>Kyohei Atarashi, Maji Subhransu, and Satoshi Oyama. Random feature maps for the itemset kernel. In <em>Proceedings of the Thirty-Third AAAI Conference on Artificial Intelligence</em>. 2019.</p>
</dd>
<dt class="bibtex label" id="bottou2010large"><span class="brackets"><a class="fn-backref" href="#id18">Bot10</a></span></dt>
<dd><p>Léon Bottou. Large-scale machine learning with stochastic gradient descent. In <em>Proceedings of COMPSTAT’2010</em>, pages 177–186. Springer, 2010.</p>
</dd>
<dt class="bibtex label" id="bottou2012stochastic"><span class="brackets"><a class="fn-backref" href="#id19">Bot12</a></span></dt>
<dd><p>Léon Bottou. Stochastic gradient descent tricks. In <em>Neural Networks: Tricks of the Trade</em>, pages 421–436. Springer, 2012.</p>
</dd>
<dt class="bibtex label" id="chang2008coordinate"><span class="brackets"><a class="fn-backref" href="#id14">CHL08</a></span></dt>
<dd><p>Kai-Wei Chang, Cho-Jui Hsieh, and Chih-Jen Lin. Coordinate descent method for large-scale l2-loss linear support vector machines. <em>Journal of Machine Learning Research</em>, 9(Jul):1369–1398, 2008.</p>
</dd>
<dt class="bibtex label" id="defazio2014saga"><span class="brackets"><a class="fn-backref" href="#id20">DBLJ14</a></span></dt>
<dd><p>Aaron Defazio, Francis Bach, and Simon Lacoste-Julien. Saga: a fast incremental gradient method with support for non-strongly convex composite objectives. In <em>Advances in Neural Information Processing Systems</em>, 1646–1654. 2014.</p>
</dd>
<dt class="bibtex label" id="duchi2011adaptive"><span class="brackets"><a class="fn-backref" href="#id15">DHS11</a></span></dt>
<dd><p>John Duchi, Elad Hazan, and Yoram Singer. Adaptive subgradient methods for online learning and stochastic optimization. <em>Journal of Machine Learning Research</em>, 12(Jul):2121–2159, 2011.</p>
</dd>
<dt class="bibtex label" id="feng2015random"><span class="brackets"><a class="fn-backref" href="#id6">FHL15</a></span></dt>
<dd><p>Chang Feng, Qinghua Hu, and Shizhong Liao. Random feature mapping with signed circulant matrix projection. In <em>Proceedings of the Twenty-Fourth International Joint Conference on Artificial Intelligence</em>. 2015.</p>
</dd>
<dt class="bibtex label" id="hamid2014compact"><span class="brackets"><a class="fn-backref" href="#id10">HXGD14</a></span></dt>
<dd><p>Raffay Hamid, Ying Xiao, Alex Gittens, and Dennis DeCoste. Compact random feature maps. In <em>Proceedings of the International Conference on Machine Learning</em>, 19–27. 2014.</p>
</dd>
<dt class="bibtex label" id="kar2012random"><span class="brackets"><a class="fn-backref" href="#id2">KK12</a></span></dt>
<dd><p>Purushottam Kar and Harish Karnick. Random feature maps for dot product kernel. In <em>Proceedings of the Artificial Inteligence and Statistics</em>, 583–591. 2012.</p>
</dd>
<dt class="bibtex label" id="kingma2014adam"><span class="brackets"><a class="fn-backref" href="#id17">KB15</a></span></dt>
<dd><p>Diederik P Kingma and Jimmy Ba. Adam: a method for stochastic optimization. In <em>Proceedings of the International Conference on Learning Representations</em>. 2015.</p>
</dd>
<dt class="bibtex label" id="le2013fastfood"><span class="brackets"><a class="fn-backref" href="#id9">LSarlosS13</a></span></dt>
<dd><p>Quoc Le, Tamás Sarlós, and Alex Smola. Fastfood-approximating kernel expansions in loglinear time. In <em>Proceedings of the International Conference on Machine Learning</em>, volume 85. 2013.</p>
</dd>
<dt class="bibtex label" id="li2006very"><span class="brackets"><a class="fn-backref" href="#id11">LHC06</a></span></dt>
<dd><p>Ping Li, Trevor J Hastie, and Kenneth W Church. Very sparse random projections. In <em>Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</em>, 287–296. ACM, 2006.</p>
</dd>
<dt class="bibtex label" id="maji2009max"><span class="brackets">MB09</span><span class="fn-backref">(<a href="#id5">1</a>,<a href="#id13">2</a>)</span></dt>
<dd><p>Subhransu Maji and Alexander C Berg. Max-margin additive classifiers for detection. In <em>Proceedings of the IEEE International Conference on Computer Vision</em>, 40–47. IEEE, 2009.</p>
</dd>
<dt class="bibtex label" id="pham2013fast"><span class="brackets"><a class="fn-backref" href="#id3">PP13</a></span></dt>
<dd><p>Ninh Pham and Rasmus Pagh. Fast and scalable polynomial kernels via explicit feature maps. In <em>Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</em>, 239–247. ACM, 2013.</p>
</dd>
<dt class="bibtex label" id="rahimi2008random"><span class="brackets"><a class="fn-backref" href="#id1">RR08</a></span></dt>
<dd><p>Ali Rahimi and Benjamin Recht. Random features for large-scale kernel machines. In <em>Proceedings of the Advances in Neural Information Processing Systems</em>, 1177–1184. 2008.</p>
</dd>
<dt class="bibtex label" id="schmidt2017minimizing"><span class="brackets"><a class="fn-backref" href="#id21">SLRB17</a></span></dt>
<dd><p>Mark Schmidt, Nicolas Le Roux, and Francis Bach. Minimizing finite sums with the stochastic average gradient. <em>Mathematical Programming</em>, 162(1-2):83–112, 2017.</p>
</dd>
<dt class="bibtex label" id="shalev2013stochastic"><span class="brackets"><a class="fn-backref" href="#id16">SSZ13</a></span></dt>
<dd><p>Shai Shalev-Shwartz and Tong Zhang. Stochastic dual coordinate ascent methods for regularized loss minimization. <em>Journal of Machine Learning Research</em>, 14(Feb):567–599, 2013.</p>
</dd>
<dt class="bibtex label" id="tropp2011improved"><span class="brackets"><a class="fn-backref" href="#id8">Tro11</a></span></dt>
<dd><p>Joel A Tropp. Improved analysis of the subsampled randomized hadamard transform. <em>Advances in Adaptive Data Analysis</em>, 3(01n02):115–126, 2011.</p>
</dd>
<dt class="bibtex label" id="yu2016orthogonal"><span class="brackets"><a class="fn-backref" href="#id12">YSC+16</a></span></dt>
<dd><p>Felix Xinnan X Yu, Ananda Theertha Suresh, Krzysztof M Choromanski, Daniel N Holtmann-Rice, and Sanjiv Kumar. Orthogonal random features. In <em>Proceedings of the Advances in Neural Information Processing Systems</em>, 1975–1983. 2016.</p>
</dd>
</dl>
</p>
</div>
<div class="section" id="authors">
<h2>Authors<a class="headerlink" href="#authors" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Kyohei Atarashi, 2018-present</p></li>
</ul>
<div class="toctree-wrapper compound">
</div>
</div>
</div>
<div class="section" id="indices-and-tables">
<h1>Indices and tables<a class="headerlink" href="#indices-and-tables" title="Permalink to this headline">¶</a></h1>
<ul class="simple">
<li><p><a class="reference internal" href="genindex.html"><span class="std std-ref">Index</span></a></p></li>
<li><p><a class="reference internal" href="py-modindex.html"><span class="std std-ref">Module Index</span></a></p></li>
<li><p><a class="reference internal" href="search.html"><span class="std std-ref">Search Page</span></a></p></li>
</ul>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="linear_model.html" class="btn btn-neutral float-right" title="Linear models" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Kyohei Atarashi

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>